{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14075,
     "status": "ok",
     "timestamp": 1752748928523,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "1qHaQFjhseNP",
    "outputId": "4dc854a0-588b-4b13-d41f-0cecbef17143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\usuario\\miniforge3\\lib\\site-packages (4.53.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\usuario\\miniforge3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\miniforge3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario\\miniforge3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\usuario\\miniforge3\\lib\\site-packages (3.0.2)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (0.34.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from torch) (80.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\miniforge3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets scikit-learn pandas xgboost torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752748928532,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "McXj4N7AsFmY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\miniforge3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Subset, Dataset\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertForSequenceClassification\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdamW\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from google.colab import drive\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1752748928534,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "ftNMFOA_sVIa"
   },
   "outputs": [],
   "source": [
    "class EsquizofreniaDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1773,
     "status": "ok",
     "timestamp": 1752748930309,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "i6Jt67EqjbDa",
    "outputId": "377a0e55-f250-4fd0-c619-24c0a5abf51c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "ruta_dataset = '/content/drive/MyDrive/ALBA/diagnosticos_F20_F20.89_con_descripcion.csv'\n",
    "df = pd.read_csv(ruta_dataset, sep=\"|\")\n",
    "model_type = \"dccuchile/bert-base-spanish-wwm-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1752748930388,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "obZ2JP3Os5Ng",
    "outputId": "854def00-ca89-456f-8b0a-0e324b914da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in DIAG PSQ: ['Otros tipos de esquizofrenia' 'Esquizofrenia' 'No encontrado']\n",
      "Dataset size after removing NaN labels: 2277\n"
     ]
    }
   ],
   "source": [
    "# Reemplaza espacios innecesarios en los nombres de columna\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Unir las 20 columnas de diagnóstico en una sola cadena de texto por fila\n",
    "diag_columns = [col for col in df.columns if col.startswith(\"Diag\")]\n",
    "df[\"text\"] = df[diag_columns].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "print(\"Unique values in DIAG PSQ:\", df[\"DIAG PSQ\"].unique())\n",
    "\n",
    "df[\"label\"] = df[\"DIAG PSQ\"].map({\n",
    "    \"Esquizofrenia\": 1,\n",
    "    \"Otros tipos de esquizofrenia\": 0\n",
    "})\n",
    "\n",
    "# Remove rows with NaN labels\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "print(f\"Dataset size after removing NaN labels: {len(df)}\")\n",
    "\n",
    "# Convert to int to ensure no floating point issues\n",
    "df[\"label\"] = df[\"label\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2647,
     "status": "ok",
     "timestamp": 1752748933037,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "-ayBDbmis8i9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "labels = df[\"label\"].tolist()\n",
    "# Tokenizamos los textos\n",
    "encodings = tokenizer(\n",
    "    df[\"text\"].tolist(),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "\n",
    "# Ruta donde guardar\n",
    "save_path = \"/content/drive/MyDrive/ALBA/resultados/\" + model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7484,
     "status": "ok",
     "timestamp": 1752748940513,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "8zO2agUXtEJD",
    "outputId": "1d6be1ae-840c-486e-ff17-375f988d508c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/content/drive/MyDrive/ALBA/resultados/dccuchile/bert-base-spanish-wwm-cased/tokenizer_config.json',\n",
       " '/content/drive/MyDrive/ALBA/resultados/dccuchile/bert-base-spanish-wwm-cased/special_tokens_map.json',\n",
       " '/content/drive/MyDrive/ALBA/resultados/dccuchile/bert-base-spanish-wwm-cased/vocab.txt',\n",
       " '/content/drive/MyDrive/ALBA/resultados/dccuchile/bert-base-spanish-wwm-cased/added_tokens.json',\n",
       " '/content/drive/MyDrive/ALBA/resultados/dccuchile/bert-base-spanish-wwm-cased/tokenizer.json')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = EsquizofreniaDataset(encodings, labels)\n",
    "\n",
    "# Índices para separar\n",
    "train_indices, test_indices = train_test_split(\n",
    "    list(range(len(dataset))),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Crear subsets\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Cargar en DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_type,\n",
    "    num_labels=2  # 2 clases: F20 (1) y F20.89 (0)\n",
    ")\n",
    "\n",
    "# Guardar modelo y tokenizador\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591725,
     "status": "ok",
     "timestamp": 1752749532238,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "5AVWZ5pDtF95",
    "outputId": "e155bd57-6038-4049-a373-848ece57751b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 228/228 [01:11<00:00,  3.20it/s, loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.5768945789650867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 228/228 [01:12<00:00,  3.14it/s, loss=0.333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.47276206791662334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 228/228 [01:13<00:00,  3.09it/s, loss=0.448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.38968559030214683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 228/228 [01:14<00:00,  3.06it/s, loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.328384897426555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 228/228 [01:14<00:00,  3.05it/s, loss=0.0366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.2957181418314576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 228/228 [01:14<00:00,  3.05it/s, loss=0.592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 0.2549937566917945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 228/228 [01:14<00:00,  3.04it/s, loss=0.238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 0.2407357290340179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 228/228 [01:14<00:00,  3.04it/s, loss=0.79]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 0.22701568664878755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Entrenamiento simple\n",
    "model.train()\n",
    "for epoch in range(8):  # puedes ajustar el número de épocas\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1} loss: {total_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6062,
     "status": "ok",
     "timestamp": 1752749538319,
     "user": {
      "displayName": "Raúl Fernández Rodríguez",
      "userId": "16917988469537735648"
     },
     "user_tz": -120
    },
    "id": "AUSLHC4stPvW",
    "outputId": "2525439a-71d1-40fe-c63d-f457b0700140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      F20.89       0.80      0.93      0.86       307\n",
      "         F20       0.79      0.52      0.63       149\n",
      "\n",
      "    accuracy                           0.80       456\n",
      "   macro avg       0.79      0.73      0.75       456\n",
      "weighted avg       0.80      0.80      0.79       456\n",
      "\n",
      "[[286  21]\n",
      " [ 71  78]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Resultados\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"F20.89\", \"F20\"]))\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMUBRBrUzixl7HoxPcxuzlI",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "alba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
