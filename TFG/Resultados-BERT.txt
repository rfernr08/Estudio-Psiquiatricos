üèÜ Mejores resultados por F1:
             modelo  learning_rate  batch_size  epochs  accuracy        f1  \
3  xlm-roberta-base        0.00005          16       4  0.701299  0.584337   
1  xlm-roberta-base        0.00003          16       3  0.653680  0.370079   
0  xlm-roberta-base        0.00002          16       3  0.658009  0.362903   
2  xlm-roberta-base        0.00003          32       3  0.658009  0.362903   

   precision    recall  
3   0.530055  0.651007  
1   0.447619  0.315436  
0   0.454545  0.302013  
2   0.454545  0.302013  

üìä Mejores modelos por score combinado (f1 + recall):
             modelo  learning_rate  batch_size  epochs  accuracy        f1  \
3  xlm-roberta-base        0.00005          16       4  0.701299  0.584337   
1  xlm-roberta-base        0.00003          16       3  0.653680  0.370079   
0  xlm-roberta-base        0.00002          16       3  0.658009  0.362903   
2  xlm-roberta-base        0.00003          32       3  0.658009  0.362903   

   precision    recall     score  
3   0.530055  0.651007  0.611005  
1   0.447619  0.315436  0.348222  
0   0.454545  0.302013  0.338547  
2   0.454545  0.302013  0.338547  




üèÜ Mejores resultados por F1:
                                  modelo  learning_rate  batch_size  epochs  \
3  dccuchile/bert-base-spanish-wwm-cased        0.00005          16       4   
1  dccuchile/bert-base-spanish-wwm-cased        0.00003          16       3   
2  dccuchile/bert-base-spanish-wwm-cased        0.00003          32       3   
0  dccuchile/bert-base-spanish-wwm-cased        0.00002          16       3   

   accuracy        f1  precision    recall  
3  0.768398  0.660317   0.626506  0.697987  
1  0.744589  0.601351   0.605442  0.597315  
2  0.757576  0.525424   0.712644  0.416107  
0  0.722944  0.479675   0.608247  0.395973  

üìä Mejores modelos por score combinado (f1 + recall):
                                  modelo  learning_rate  batch_size  epochs  \
3  dccuchile/bert-base-spanish-wwm-cased        0.00005          16       4   
1  dccuchile/bert-base-spanish-wwm-cased        0.00003          16       3   
2  dccuchile/bert-base-spanish-wwm-cased        0.00003          32       3   
0  dccuchile/bert-base-spanish-wwm-cased        0.00002          16       3   

   accuracy        f1  precision    recall     score  
3  0.768398  0.660317   0.626506  0.697987  0.675385  
1  0.744589  0.601351   0.605442  0.597315  0.599737  
2  0.757576  0.525424   0.712644  0.416107  0.481697  
0  0.722944  0.479675   0.608247  0.395973  0.446194 

üèÜ Mejores resultados por F1:
                                    modelo  learning_rate  batch_size  epochs  \
2  dccuchile/bert-base-spanish-wwm-uncased        0.00003          32       3   
3  dccuchile/bert-base-spanish-wwm-uncased        0.00005          16       4   
1  dccuchile/bert-base-spanish-wwm-uncased        0.00003          16       3   
0  dccuchile/bert-base-spanish-wwm-uncased        0.00002          16       3   

   accuracy        f1  precision    recall  
2  0.744589  0.616883   0.597484  0.637584  
3  0.779221  0.571429   0.764045  0.456376  
1  0.783550  0.568966   0.795181  0.442953  
0  0.766234  0.538462   0.741176  0.422819  

üìä Mejores modelos por score combinado (f1 + recall):
                                    modelo  learning_rate  batch_size  epochs  \
2  dccuchile/bert-base-spanish-wwm-uncased        0.00003          32       3   
3  dccuchile/bert-base-spanish-wwm-uncased        0.00005          16       4   
1  dccuchile/bert-base-spanish-wwm-uncased        0.00003          16       3   
0  dccuchile/bert-base-spanish-wwm-uncased        0.00002          16       3   

   accuracy        f1  precision    recall     score  
2  0.744589  0.616883   0.597484  0.637584  0.625163  
3  0.779221  0.571429   0.764045  0.456376  0.525407  
1  0.783550  0.568966   0.795181  0.442953  0.518561  
0  0.766234  0.538462   0.741176  0.422819  0.492204 


üèÜ Mejores resultados por F1:
                         modelo  learning_rate  batch_size  epochs  accuracy  \
0  bert-base-multilingual-cased        0.00002          16       3  0.766234   
3  bert-base-multilingual-cased        0.00005          16       4  0.770563   
1  bert-base-multilingual-cased        0.00003          16       3  0.748918   
2  bert-base-multilingual-cased        0.00003          32       3  0.738095   

         f1  precision    recall  
0  0.651613   0.627329  0.677852  
3  0.572581   0.717172  0.476510  
1  0.508475   0.689655  0.402685  
2  0.489451   0.659091  0.389262  

üìä Mejores modelos por score combinado (f1 + recall):
                         modelo  learning_rate  batch_size  epochs  accuracy  \
0  bert-base-multilingual-cased        0.00002          16       3  0.766234   
3  bert-base-multilingual-cased        0.00005          16       4  0.770563   
1  bert-base-multilingual-cased        0.00003          16       3  0.748918   
2  bert-base-multilingual-cased        0.00003          32       3  0.738095   

         f1  precision    recall     score  
0  0.651613   0.627329  0.677852  0.662109  
3  0.572581   0.717172  0.476510  0.534152  
1  0.508475   0.689655  0.402685  0.466159  
2  0.489451   0.659091  0.389262  0.449376 
