üèÜ Mejores resultados por F1:
                                     modelo  learning_rate  batch_size  \
16    dccuchile/bert-base-spanish-wwm-cased        0.00002          16   
8   dccuchile/bert-base-spanish-wwm-uncased        0.00002          16   
9   dccuchile/bert-base-spanish-wwm-uncased        0.00002          32   
21    dccuchile/bert-base-spanish-wwm-cased        0.00005          32   
10  dccuchile/bert-base-spanish-wwm-uncased        0.00003          16   
17    dccuchile/bert-base-spanish-wwm-cased        0.00002          32   
0              bert-base-multilingual-cased        0.00002          16   
19    dccuchile/bert-base-spanish-wwm-cased        0.00003          32   
26                         xlm-roberta-base        0.00003          16   
20    dccuchile/bert-base-spanish-wwm-cased        0.00003          64   

    epochs  accuracy        f1  precision    recall  
16       5    0.8325  0.702222   0.774510  0.642276  
8        5    0.8075  0.693227   0.679688  0.707317  
9        5    0.8100  0.691057   0.691057  0.691057  
21       3    0.8200  0.689655   0.733945  0.650407  
10       4    0.8225  0.681614   0.760000  0.617886  
17       5    0.8200  0.678571   0.752475  0.617886  
0        5    0.7950  0.663934   0.669421  0.658537  
19       4    0.8050  0.635514   0.747253  0.552846  
26       4    0.7925  0.634361   0.692308  0.585366  
20       4    0.7825  0.609865   0.680000  0.552846  

üìä Mejores modelos por score combinado (f1 + recall):
                                     modelo  learning_rate  batch_size  \
8   dccuchile/bert-base-spanish-wwm-uncased        0.00002          16   
9   dccuchile/bert-base-spanish-wwm-uncased        0.00002          32   
16    dccuchile/bert-base-spanish-wwm-cased        0.00002          16   
21    dccuchile/bert-base-spanish-wwm-cased        0.00005          32   
0              bert-base-multilingual-cased        0.00002          16   
10  dccuchile/bert-base-spanish-wwm-uncased        0.00003          16   
17    dccuchile/bert-base-spanish-wwm-cased        0.00002          32   
26                         xlm-roberta-base        0.00003          16   
19    dccuchile/bert-base-spanish-wwm-cased        0.00003          32   
13  dccuchile/bert-base-spanish-wwm-uncased        0.00005          32   

    epochs  accuracy        f1  precision    recall     score  
8        5    0.8075  0.693227   0.679688  0.707317  0.698863  
9        5    0.8100  0.691057   0.691057  0.691057  0.691057  
16       5    0.8325  0.702222   0.774510  0.642276  0.678244  
21       3    0.8200  0.689655   0.733945  0.650407  0.673956  
0        5    0.7950  0.663934   0.669421  0.658537  0.661775  
10       4    0.8225  0.681614   0.760000  0.617886  0.656123  
17       5    0.8200  0.678571   0.752475  0.617886  0.654297  
26       4    0.7925  0.634361   0.692308  0.585366  0.614763  
19       4    0.8050  0.635514   0.747253  0.552846  0.602447  
13       3    0.7300  0.584615   0.554745  0.617886  0.597924 